{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95bf8243-96a4-445b-bdbc-d6f36a83158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d82bc-ff29-4df1-8a80-834256706541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SENT.csv...\n",
      "Read 2306 rows from SENT.csv.\n",
      "Columns: ['Date', 'Daily_Sum_RavenPack', 'Csum_RavenPack', 'Daily_Sum_FinBERT', 'Csum_FinBERT', 'Daily_Sum_CrudeBERT', 'Csum_CrudeBERT', 'Daily_Sum_CrudeBERT_GT', 'Csum_CrudeBERT_GT', 'Daily_Sum_CrudeBERT_Plus', 'Csum_CrudeBERT_Plus', 'Daily_Sum_CrudeBERT_Plus_GT', 'Csum_CrudeBERT_Plus_GT']\n",
      "Reading brent_processed_data.csv...\n",
      "Read 3740 rows from brent_processed_data.csv.\n",
      "Columns: ['Date', 'Close', 'Volume']\n",
      "Converting 'Date' columns to datetime objects...\n",
      "Normalizing dates (removing time component)...\n",
      "Converting 'Close' and 'Volume' to numeric...\n",
      "Merging dataframes on 'Date'...\n",
      "Merged dataframe has 2306 rows.\n",
      "Sorting merged data by date...\n",
      "Calculating price and volume differences...\n",
      "Saving results to SENT_process.csv...\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Define input and output filenames\n",
    "sentiment_file = 'SENT.csv'\n",
    "brent_file = 'Final brent_processed_data.csv' # Assuming this file exists with Date, Close, Volume columns\n",
    "USDX_file = 'Final USDX_processed_data'\n",
    "output_file = 'SENT_process.csv'\n",
    "\n",
    "try:\n",
    "    print(f\"Reading {sentiment_file}...\")\n",
    "    sent_df = pd.read_csv(sentiment_file)\n",
    "    print(f\"Read {len(sent_df)} rows from {sentiment_file}.\")\n",
    "    print(f\"Columns: {sent_df.columns.tolist()}\")\n",
    "\n",
    "    print(f\"Reading {brent_file}...\")\n",
    "    brent_df = pd.read_csv(brent_file)\n",
    "    print(f\"Read {len(brent_df)} rows from {brent_file}.\")\n",
    "    print(f\"Columns: {brent_df.columns.tolist()}\")\n",
    "\n",
    "    # --- Data Cleaning and Preparation ---\n",
    "    # Ensure required columns exist\n",
    "    required_sent_cols = ['Date','Daily_Sum_RavenPack','Csum_RavenPack','Daily_Sum_FinBERT','Csum_FinBERT','Daily_Sum_CrudeBERT','Csum_CrudeBERT','Daily_Sum_CrudeBERT_GT','Csum_CrudeBERT_GT','Daily_Sum_CrudeBERT_Plus','Csum_CrudeBERT_Plus','Daily_Sum_CrudeBERT_Plus_GT','Csum_CrudeBERT_Plus_GT']\n",
    "    required_brent_cols = ['Date', 'Close', 'Volume']\n",
    "    if not all(col in sent_df.columns for col in required_sent_cols):\n",
    "        print(f\"Error: Missing required columns in {sentiment_file}. Expected: {required_sent_cols}\")\n",
    "        sys.exit(1)\n",
    "    if not all(col in brent_df.columns for col in required_brent_cols):\n",
    "        print(f\"Error: Missing required columns in {brent_file}. Expected: {required_brent_cols}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Convert 'Date' columns to datetime objects\n",
    "    # Using errors='coerce' will turn unparseable dates into NaT (Not a Time)\n",
    "    print(\"Converting 'Date' columns to datetime objects...\")\n",
    "    sent_df['Date'] = pd.to_datetime(sent_df['Date'], errors='coerce')\n",
    "    brent_df['Date'] = pd.to_datetime(brent_df['Date'], errors='coerce')\n",
    "\n",
    "    # Normalize dates to remove time component before merging\n",
    "    print(\"Normalizing dates (removing time component)...\")\n",
    "    sent_df['Date'] = sent_df['Date'].dt.normalize()\n",
    "    brent_df['Date'] = brent_df['Date'].dt.normalize()\n",
    "\n",
    "    # Drop rows where date conversion failed\n",
    "    sent_rows_before = len(sent_df)\n",
    "    brent_rows_before = len(brent_df)\n",
    "    sent_df.dropna(subset=['Date'], inplace=True)\n",
    "    brent_df.dropna(subset=['Date'], inplace=True)\n",
    "    if len(sent_df) < sent_rows_before:\n",
    "        print(f\"Warning: Dropped {sent_rows_before - len(sent_df)} rows from {sentiment_file} due to invalid dates.\")\n",
    "    if len(brent_df) < brent_rows_before:\n",
    "        print(f\"Warning: Dropped {brent_rows_before - len(brent_df)} rows from {brent_file} due to invalid dates.\")\n",
    "\n",
    "    # Ensure 'Close' and 'Volume' are numeric, coercing errors\n",
    "    print(\"Converting 'Close' and 'Volume' to numeric...\")\n",
    "    brent_df['Close'] = pd.to_numeric(brent_df['Close'], errors='coerce')\n",
    "    brent_df['Volume'] = pd.to_numeric(brent_df['Volume'], errors='coerce')\n",
    "    brent_df.dropna(subset=['Close', 'Volume'], inplace=True) # Drop rows where conversion failed\n",
    "\n",
    "    # --- Merge DataFrames ---\n",
    "    print(\"Merging dataframes on 'Date'...\")\n",
    "    # Using an inner merge keeps only dates present in both files\n",
    "    merged_df = pd.merge(sent_df, brent_df, on='Date', how='inner')\n",
    "    print(f\"Merged dataframe has {len(merged_df)} rows.\")\n",
    "\n",
    "    if len(merged_df) == 0:\n",
    "        print(\"Error: No matching dates found between the two files. Cannot proceed.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Sort by date to ensure correct difference calculation\n",
    "    print(\"Sorting merged data by date...\")\n",
    "    merged_df.sort_values(by='Date', inplace=True)\n",
    "\n",
    "    # --- Calculate Differences ---\n",
    "    print(\"Calculating price and volume differences...\")\n",
    "    # .diff() calculates the difference between the current row and the previous row\n",
    "    merged_df['Price_Difference'] = merged_df['Close'].diff()\n",
    "    merged_df['Volume_Difference'] = merged_df['Volume'].diff()\n",
    "\n",
    "    # The first row will have NaN for differences, which is expected\n",
    "\n",
    "    # --- Select and Order Columns ---\n",
    "    output_columns = ['Date', 'BRENT Close', 'BRENT Volume', 'USDX Close','USDX Volume','Price_Difference', 'Volume_Difference','Daily_Sum_RavenPack','Csum_RavenPack','Daily_Sum_FinBERT','Csum_FinBERT','Daily_Sum_CrudeBERT','Csum_CrudeBERT','Daily_Sum_CrudeBERT_GT','Csum_CrudeBERT_GT','Daily_Sum_CrudeBERT_Plus','Csum_CrudeBERT_Plus','Daily_Sum_CrudeBERT_Plus_GT','Csum_CrudeBERT_Plus_GT']\n",
    "    final_df = merged_df[output_columns]\n",
    "\n",
    "    # --- Save Output ---\n",
    "    print(f\"Saving results to {output_file}...\")\n",
    "    final_df.to_csv(output_file, index=False, date_format='%Y-%m-%d %H:%M:%S') # Keep original date format if possible\n",
    "\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found - {e}. Please ensure both '{sentiment_file}' and '{brent_file}' exist.\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0edf8ce-1421-4f26-89b1-cccd32dad775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
